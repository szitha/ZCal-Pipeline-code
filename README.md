# ZCal-Pipeline-code
Machine learning algorithm for calibrating radio interferometric data using sensor data.

The applications of machine learning have created an opportunity to deal with complex problems currently encountered in radio astronomy data processing. Calibration is one of the most important data processing steps required to produce high dynamic range images. This process involves the determination of calibration parameters, both instrumental and astronomical, to correct the
collected data. These parameters include instrumental as well as astronomical parameters. Typically, astronomers use a package such as Common Astronomy Software Applications (CASA) to compute the gain solutions based on regular observations of a known calibrator source. In this work we present applications of machine learning to first generation calibration (1GC), using the KAT-7 telescope environmental and pointing sensor data recorded during observations. Applying machine learning to 1GC, as opposed to calculating the gain solutions in CASA, has shown evidence of reducing computation, as well as accurately predict the 1GC gain solutions and antenna behaviour. These methods are computationally less expensive, however they have not fully learned to generalise  in predicting  accurate 1GC solutions by looking at environmental and pointing sensors. We call this multi-output regression model $\textit{ZCal}$, which is based on random forest, decision trees, extremely randomized trees and K-nearest neighbor algorithms. The prediction error obtained during the testing of our model on testing data is $$\approx$$ $$0.01< \mathrm{rms}_\mathrm{e} <0.09$$ for gain amplitude per antenna, and 0.2 $$\mathrm{rad}< \mathrm{rms}_\mathrm{e}<$$0.5 $$\mathrm{rad}$$ for gain phase. This shows that the instrumental parameters used to train our model strongly correlate with gain amplitude effects than phase.  
